{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bgtfN1Dcz6qn"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "with open('gpt_key.txt', 'r') as file:\n",
        "    openai.api_key = file.read().rstrip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temperature\n",
        "So, temperature ranges from 0.0-1.0, where 0.0 has no randomness, and 1.0 allows GPT-3 to be very \"creative.\" Temperature=0.0 will give the same exact result each time. For most natural language generation tasks, people set temperature at ~0.7. We can set it at 0.3 (which is good at just giving binary answers), and maybe also try values of 0.5, and 0.7 for comparison (which will probably involve us parsing some responses)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "temperature = 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interact with GPT3 (binary true or false)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('medmcqa_train.csv')\n",
        "subject_rows = {}\n",
        "for idx, row in df.iterrows():\n",
        "    subject_rows[row['subject']] = row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_small = df.sample(n=4)\n",
        "df = df_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct answer:D\n",
            "\n",
            "(A) Vitamin D\n",
            "\n",
            "Cholesterol is not a precursor for the synthesis\n",
            "\n",
            "about this question. Cholesterol is a type of lipid, or fat. It\n",
            "\n",
            "Ans. is 'D' i.e., Lipocortin *\n",
            "\n",
            "\n",
            "Correct answer:C\n",
            "\n",
            "C. Mandibular nerve\n",
            "\n",
            "The jugular foramen is a hole\n",
            "\n",
            "to answer this question. The jugular foramen is an opening in the skull\n",
            "\n",
            "'Answer is D i.e., Internal jugular vein.o Jug\n",
            "\n",
            "\n",
            "Correct answer:D\n",
            "\n",
            "B. Water is available at a depth of more than 15 metres.\n",
            "This\n",
            "\n",
            "through the options. \n",
            "Option A is a problem village, as it is\n",
            "\n",
            "'D' is the correct answer. \"Problem village\" include all of the\n",
            "\n",
            "\n",
            "Correct answer:C\n",
            "\n",
            "(C) Intensity of stimulus and sensation felt\n",
            "\n",
            "Weber-F\n",
            "\n",
            "about this question. Weber Fechner law is a psychophysical law that states\n",
            "\n",
            "Answer: 'C' is therefore the answer, among A through D. Weber\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "verbose = True\n",
        "\n",
        "def suffix():\n",
        "    return \"\"\" is therefore the answer, among A through D.\"\"\"\n",
        "\n",
        "\n",
        "def zero_shot_empty(question):\n",
        "    return f\"\"\"\n",
        "    Question: '{question}'\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "def zero_shot_CoT(question):\n",
        "    return f\"\"\"\n",
        "    Question: '{question}'\n",
        "    Answer: Let's think step by step \"\"\"\n",
        "\n",
        "def zero_shot_empty_plus_grounding(question, context):\n",
        "    return f\"\"\"\n",
        "    Context: '{context}'\n",
        "    Question: '{question}'\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "def one_shot(question, shot_question, shot_explanation, shot_answer):\n",
        "    return f\"\"\"\n",
        "    Question: '{shot_question}'\n",
        "    Answer: Let's think step by step. '{shot_explanation}'\n",
        "    '{shot_answer}' is therefore the answer, among A through D.\n",
        "\n",
        "    Question: '{question}'\n",
        "    Answer: Let's think step by step\n",
        "    \"\"\"\n",
        "\n",
        "def correct_letter(correct_answer, text_answer):\n",
        "    text_answer = text_answer.lower().split(' ')\n",
        "    if correct_answer == 'A':\n",
        "        if 'a' in text_answer:\n",
        "            return 1\n",
        "    if correct_answer == 'B':\n",
        "        if 'b' in text_answer:\n",
        "            return 1\n",
        "    if correct_answer == 'C':\n",
        "        if 'c' in text_answer:\n",
        "            return 1\n",
        "    if correct_answer == 'D':\n",
        "        if 'd' in text_answer:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def score_row(row):\n",
        "    zero_shot_empty_answer = openai.Completion.create(\n",
        "                engine = \"text-davinci-003\", #text-davinci-003 davinci-instruct-beta\n",
        "                prompt = zero_shot_empty(row['question']),\n",
        "                suffix = suffix(),\n",
        "                temperature = temperature)\n",
        "\n",
        "    zero_shot_CoT_answer = openai.Completion.create(\n",
        "                engine = \"text-davinci-003\", #text-davinci-003\n",
        "                prompt = zero_shot_CoT(row['question']),\n",
        "                suffix = suffix(),\n",
        "                temperature = temperature)\n",
        "\n",
        "    # zero_shot_empty_plus_grounding_answer = openai.Completion.create(\n",
        "    #             engine = \"text-davinci-001\",\n",
        "    #             prompt = zero_shot_empty_plus_grounding(row['question'], row['question']),\n",
        "    #             temperature = temperature)\n",
        "\n",
        "    example_row = subject_rows[row['subject']]\n",
        "\n",
        "    one_shot_answer = openai.Completion.create(\n",
        "                engine = \"text-davinci-003\",\n",
        "                prompt = one_shot(row['question'], \n",
        "                                  example_row['question'],\n",
        "                                  example_row['explanation'],\n",
        "                                  example_row['answer_letter']),\n",
        "                suffix = suffix(),\n",
        "                temperature = temperature)\n",
        "\n",
        "    if verbose:\n",
        "        print('Correct answer:' + row['answer_letter'])\n",
        "        print()\n",
        "        print(zero_shot_empty_answer[\"choices\"][0][\"text\"])\n",
        "        print()\n",
        "        print(zero_shot_CoT_answer[\"choices\"][0][\"text\"])\n",
        "        print()\n",
        "        print(one_shot_answer[\"choices\"][0][\"text\"])\n",
        "        print()\n",
        "        print()\n",
        "\n",
        "    return {\n",
        "        'zero_shot_empty': correct_letter(row['answer_letter'], zero_shot_empty_answer[\"choices\"][0][\"text\"]),\n",
        "        'zero_shot_CoT': correct_letter(row['answer_letter'], zero_shot_CoT_answer[\"choices\"][0][\"text\"]),\n",
        "        'one_shot': correct_letter(row['answer_letter'], one_shot_answer[\"choices\"][0][\"text\"])\n",
        "    }\n",
        "\n",
        "r = df.apply(lambda row: score_row(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'zero_shot_empty': 0, 'zero_shot_CoT': 0, 'one_shot': 0}\n",
            "{'zero_shot_empty': 0, 'zero_shot_CoT': 0, 'one_shot': 0}\n",
            "{'zero_shot_empty': 0, 'zero_shot_CoT': 0, 'one_shot': 0}\n",
            "{'zero_shot_empty': 0, 'zero_shot_CoT': 0, 'one_shot': 0}\n"
          ]
        }
      ],
      "source": [
        "for k, v in r.items():\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "one_shot_answer = openai.Completion.create(\n",
        "                engine = \"text-davinci-003\",\n",
        "                prompt = one_shot(row['question'], \n",
        "                                  df.iloc[2]['question'],\n",
        "                                  df.iloc[2]['explanation'],\n",
        "                                  df.iloc[2]['answer_letter']),\n",
        "                suffix = suffix(),\n",
        "                temperature = temperature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Gluten hypersensitivity is a condition in which the body reacts to gluten, a'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_shot_answer['choices'][0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "GPT-3 Prompts for Toxicity",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('heuristic_fairness')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "6597d1ed23b894caf154b6750f098a8514a19e03807460ffd2d8425103778dc0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
